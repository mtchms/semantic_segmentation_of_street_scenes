# ***DeepLabV3+ (ResNet + AttentionGate + ASPP) для сегментации Mapillary Vistas*** 
Цель модели - по снимкам улиц точно определить границы разных объектов: машины, фонарные столбцы, дороги и т. д.

![photo_5375244639046593647_w](https://github.com/user-attachments/assets/c9c3887b-b5e0-4736-a84a-225595a5041b) ![photo_5375244639046593646_w](https://github.com/user-attachments/assets/5c19cbb2-2306-43b7-b157-832591650f97)

DeepLabV3+ с Attention Gates и GroupNorm для семантической сегментации
Аннотация
Данная реализация представляет собой улучшенную версию архитектуры DeepLabV3+ для задач семантической сегментации изображений. Модель включает ResNet-подобный энкодер с bottleneck блоками, модуль Atrous Spatial Pyramid Pooling (ASPP), механизм attention gates и использует Group Normalization вместо стандартной Batch Normalization для повышения стабильности обучения на малых батчах.

Архитектура модели
1. ResNet Encoder с Bottleneck блоками
Энкодер основан на архитектуре ResNet с bottleneck блоками, которые обеспечивают эффективное извлечение признаков на разных уровнях абстракции.

Bottleneck блок состоит из трех сверточных слоев:

1
×
1
1×1 свертка для уменьшения размерности (сжатие)

3
×
3
3×3 свертка для извлечения пространственных признаков

1
×
1
1×1 свертка для восстановления размерности (расширение в 4 раза)

Каждая свертка сопровождается Group Normalization и ReLU активацией. Блок использует residual connections для облегчения обучения глубоких сетей.

Структура энкодера:

Начальная свертка 
7
×
7
7×7 со stride=2

Max pooling 
3
×
3
3×3

4 слоя с bottleneck блоками:

Layer1: 256 каналов (64 × 4)

Layer2: 512 каналов (128 × 4)

Layer3: 1024 канала (256 × 4)

Layer4: 2048 каналов (512 × 4)

Выходы всех слоев (f1, f2, f3, f4) сохраняются для skip connections в декодере.

2. ASPP (Atrous Spatial Pyramid Pooling)
ASPP модуль применяется к выходу энкодера (f4) и предназначен для захвата мультимасштабной контекстной информации.

Компоненты ASPP:

Branch 1: 
1
×
1
1×1 свертка (базовые признаки)

Branch 2: 
3
×
3
3×3 dilated свертка с dilation=6

Branch 3: 
3
×
3
3×3 dilated свертка с dilation=12

Branch 4: 
3
×
3
3×3 dilated свертка с dilation=18

Global pooling: адаптивный average pooling + 
1
×
1
1×1 свертка

Все ветви выдают 256 каналов. Выходы конкатенируются (1280 каналов) и проецируются обратно в 256 каналов через 
1
×
1
1×1 свертку с dropout (p=0.5).

Роль dilated convolutions:
Расширенные свертки увеличивают рецептивное поле без потери разрешения, позволяя модели видеть объекты разного размера.

3. Attention Gates
Механизм внимания используется для фокусировки на релевантных признаках при объединении глубоких (ASPP) и поверхностных (skip connection) features.

Математическая формулировка:

α
=
σ
(
W
ψ
(
ReLU
(
W
g
⋅
g
+
W
x
⋅
x
)
)
)
α=σ(W 
ψ
 (ReLU(W 
g
 ⋅g+W 
x
 ⋅x)))
x
^
=
x
⊙
α
x
^
 =x⊙α
где:

g
g — gating signal (выход ASPP)

x
x — skip connection (f1 из энкодера)

W
g
W 
g
 , 
W
x
W 
x
 , 
W
ψ
W 
ψ
  — обучаемые веса

σ
σ — сигмоида

⊙
⊙ — поэлементное умножение

Attention gate выделяет важные пространственные области в skip connection, подавляя нерелевантную информацию.

4. Декодер
Этапы декодирования:

ASPP выход upsampling до размера 
H
/
4
×
W
/
4
H/4×W/4 (bilinear interpolation)

Skip connection (f1) проходит через attention gate (опционально)

Skip connection редуцируется до 48 каналов через 
1
×
1
1×1 свертку

Конкатенация ASPP (256) и skip (48) → 304 канала

Два последовательных 
3
×
3
3×3 свертки с 256 каналами

Upsampling до оригинального разрешения 
H
×
W
H×W

Финальная 
1
×
1
1×1 свертка для классификации на num_classes

5. Group Normalization
Вместо Batch Normalization используется Group Normalization (GN), которая:

Не зависит от размера батча

Стабильнее при малых батчах (критично для сегментации)

Делит каналы на группы и нормализует внутри каждой группы

Функция get_num_groups автоматически подбирает оптимальное количество групп (до 32), обеспечивая делимость числа каналов.

Преимущества архитектуры
Мультимасштабное восприятие
ASPP с различными dilation rates позволяет сети эффективно обрабатывать объекты разных размеров в одном изображении.

Skip connections с attention
Прямые соединения из энкодера обеспечивают сохранение мелких деталей, а attention gates фильтруют шум и выделяют релевантные признаки.

Стабильность обучения
Group Normalization обеспечивает стабильные градиенты независимо от размера батча, что критично для задач сегментации с высоким разрешением.

Глубокая residual архитектура
Bottleneck блоки с residual connections позволяют обучать очень глубокие сети без проблемы затухающих градиентов.

Параметры модели
num_classes: количество классов сегментации (по умолчанию 124)

layers: конфигурация ResNet для ResNet-50

num_groups: максимальное количество групп для GroupNorm (32)

use_attention: включение/выключение attention gates (True)

Применение
Модель оптимизирована для:

Семантической сегментации сцен

Медицинской сегментации изображений

Сегментации объектов на аэрофотоснимках

Любых задач плотного предсказания на пиксельном уровне

Пример использования
python
model = DeepLabV3Plus(num_classes=21, layers=[3,4,6,3], use_attention=True)
input_tensor = torch.randn(1, 3, 512, 512)
output = model(input_tensor)  # Shape: [1, 21, 512, 512]
Вычислительная сложность
Параметры: ~41M (ResNet-50 backbone)

FLOPs: зависит от входного разрешения

Память: рекомендуется GPU с минимум 8GB для батча размером 4-8

Литература
Архитектура основана на:

DeepLabV3+: Encoder-Decoder with Atrous Separable Convolution

ResNet: Deep Residual Learning for Image Recognition

Attention U-Net: Learning Where to Look for the Pancreas

Group Normalization (Wu & He, 2018)


***config.py***
  Здесь все основные настройки.

***dataset.py***
  Реализация загрузки Mapillary Vistas и аугментаций (flip, rotation, color jitter).
  Здесь можно посмотреть, как формируются тензоры image, mask и как применяются преобразования.

***advanced_model.py***
  Архитектура DeepLabV3+ с модифицированным ResNet, Attention Gate и ASPP.

***utils.py***
  Служебные функции: сохранение/загрузка чекпоинтов, расчёт весов классов.

***train_advanced.py***
  Главный скрипт обучения.
  Запускает датасет, модель, оптимизатор, считает лосс, метрики, сохраняет результаты.
  После настройки config.py и проверки путей в датасете — этот файл и нужно запускать.

***outputs/***
  Сюда сохраняются веса лучшей модели (best_advanced_model.pth) и промежуточные чекпоинты.
  Можно использовать для последующего инференса или дообучения.
